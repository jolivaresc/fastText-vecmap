{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olivares/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "__author__ = \"Olivares Castillo Jos√© Luis\"\n",
    "\n",
    "#tf.enable_eager_execution()\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "#print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print(\"GPU disponible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1869 1869\n"
     ]
    }
   ],
   "source": [
    "words_scr_lexicon, words_trg_lexicon = utils.get_lexicon(\"en-it.test\")\n",
    "print(len(words_scr_lexicon), len(words_trg_lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 300)\n"
     ]
    }
   ],
   "source": [
    "source_vec = utils.open_file('en.fst')\n",
    "words_src, source_vec = utils.read(source_vec,is_zipped=False)\n",
    "eval_src = list(set(words_scr_lexicon))\n",
    "src_vec = utils.get_vectors(eval_src, words_src, source_vec)\n",
    "print(src_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199996, 300)\n"
     ]
    }
   ],
   "source": [
    "target_vec = utils.open_file(\"it.fst\")\n",
    "words_trg, target_vec = utils.read(target_vec,is_zipped=False)\n",
    "#eval_it = list(set(it))\n",
    "#trg_vec = get_vectors(eval_it, words_it, it_vec)\n",
    "print(target_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectors = src_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/en-it/1/model2250.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "path=\"models/en-it/1/\"\n",
    "saver = tf.train.import_meta_graph(path+\"model2250.ckpt.meta\")\n",
    "saver.restore(sess,tf.train.latest_checkpoint(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()\n",
    "X = graph.get_tensor_by_name(\"input/input_es:0\")\n",
    "kprob = graph.get_tensor_by_name(\"dropout_prob:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input/input_es',\n",
       " 'input/target_na',\n",
       " 'dropout_prob',\n",
       " 'h1/kernel/Initializer/truncated_normal/shape',\n",
       " 'h1/kernel/Initializer/truncated_normal/mean',\n",
       " 'h1/kernel/Initializer/truncated_normal/stddev',\n",
       " 'h1/kernel/Initializer/truncated_normal/TruncatedNormal',\n",
       " 'h1/kernel/Initializer/truncated_normal/mul',\n",
       " 'h1/kernel/Initializer/truncated_normal',\n",
       " 'h1/kernel',\n",
       " 'h1/kernel/Assign',\n",
       " 'h1/kernel/read',\n",
       " 'h1/bias/Initializer/zeros/shape_as_tensor',\n",
       " 'h1/bias/Initializer/zeros/Const',\n",
       " 'h1/bias/Initializer/zeros',\n",
       " 'h1/bias',\n",
       " 'h1/bias/Assign',\n",
       " 'h1/bias/read',\n",
       " 'h1/MatMul',\n",
       " 'h1/BiasAdd',\n",
       " 'h1/Elu',\n",
       " 'dropout/Identity',\n",
       " 'nah_predicted/kernel/Initializer/truncated_normal/shape',\n",
       " 'nah_predicted/kernel/Initializer/truncated_normal/mean',\n",
       " 'nah_predicted/kernel/Initializer/truncated_normal/stddev',\n",
       " 'nah_predicted/kernel/Initializer/truncated_normal/TruncatedNormal',\n",
       " 'nah_predicted/kernel/Initializer/truncated_normal/mul',\n",
       " 'nah_predicted/kernel/Initializer/truncated_normal',\n",
       " 'nah_predicted/kernel',\n",
       " 'nah_predicted/kernel/Assign',\n",
       " 'nah_predicted/kernel/read',\n",
       " 'nah_predicted/bias/Initializer/zeros/shape_as_tensor',\n",
       " 'nah_predicted/bias/Initializer/zeros/Const',\n",
       " 'nah_predicted/bias/Initializer/zeros',\n",
       " 'nah_predicted/bias',\n",
       " 'nah_predicted/bias/Assign',\n",
       " 'nah_predicted/bias/read',\n",
       " 'nah_predicted/MatMul',\n",
       " 'nah_predicted/BiasAdd',\n",
       " 'nah_predicted/Elu',\n",
       " 'SquaredDifference',\n",
       " 'Const',\n",
       " 'loss',\n",
       " 'loss_1/tags',\n",
       " 'loss_1',\n",
       " 'gradients/Shape',\n",
       " 'gradients/grad_ys_0',\n",
       " 'gradients/Fill',\n",
       " 'gradients/loss_grad/Reshape/shape',\n",
       " 'gradients/loss_grad/Reshape',\n",
       " 'gradients/loss_grad/Shape',\n",
       " 'gradients/loss_grad/Tile',\n",
       " 'gradients/loss_grad/Shape_1',\n",
       " 'gradients/loss_grad/Shape_2',\n",
       " 'gradients/loss_grad/Const',\n",
       " 'gradients/loss_grad/Prod',\n",
       " 'gradients/loss_grad/Const_1',\n",
       " 'gradients/loss_grad/Prod_1',\n",
       " 'gradients/loss_grad/Maximum/y',\n",
       " 'gradients/loss_grad/Maximum',\n",
       " 'gradients/loss_grad/floordiv',\n",
       " 'gradients/loss_grad/Cast',\n",
       " 'gradients/loss_grad/truediv',\n",
       " 'gradients/SquaredDifference_grad/Shape',\n",
       " 'gradients/SquaredDifference_grad/Shape_1',\n",
       " 'gradients/SquaredDifference_grad/BroadcastGradientArgs',\n",
       " 'gradients/SquaredDifference_grad/scalar',\n",
       " 'gradients/SquaredDifference_grad/mul',\n",
       " 'gradients/SquaredDifference_grad/sub',\n",
       " 'gradients/SquaredDifference_grad/mul_1',\n",
       " 'gradients/SquaredDifference_grad/Sum',\n",
       " 'gradients/SquaredDifference_grad/Reshape',\n",
       " 'gradients/SquaredDifference_grad/Sum_1',\n",
       " 'gradients/SquaredDifference_grad/Reshape_1',\n",
       " 'gradients/SquaredDifference_grad/Neg',\n",
       " 'gradients/SquaredDifference_grad/tuple/group_deps',\n",
       " 'gradients/SquaredDifference_grad/tuple/control_dependency',\n",
       " 'gradients/SquaredDifference_grad/tuple/control_dependency_1',\n",
       " 'gradients/nah_predicted/Elu_grad/EluGrad',\n",
       " 'gradients/nah_predicted/BiasAdd_grad/BiasAddGrad',\n",
       " 'gradients/nah_predicted/BiasAdd_grad/tuple/group_deps',\n",
       " 'gradients/nah_predicted/BiasAdd_grad/tuple/control_dependency',\n",
       " 'gradients/nah_predicted/BiasAdd_grad/tuple/control_dependency_1',\n",
       " 'gradients/nah_predicted/MatMul_grad/MatMul',\n",
       " 'gradients/nah_predicted/MatMul_grad/MatMul_1',\n",
       " 'gradients/nah_predicted/MatMul_grad/tuple/group_deps',\n",
       " 'gradients/nah_predicted/MatMul_grad/tuple/control_dependency',\n",
       " 'gradients/nah_predicted/MatMul_grad/tuple/control_dependency_1',\n",
       " 'gradients/h1/Elu_grad/EluGrad',\n",
       " 'gradients/h1/BiasAdd_grad/BiasAddGrad',\n",
       " 'gradients/h1/BiasAdd_grad/tuple/group_deps',\n",
       " 'gradients/h1/BiasAdd_grad/tuple/control_dependency',\n",
       " 'gradients/h1/BiasAdd_grad/tuple/control_dependency_1',\n",
       " 'gradients/h1/MatMul_grad/MatMul',\n",
       " 'gradients/h1/MatMul_grad/MatMul_1',\n",
       " 'gradients/h1/MatMul_grad/tuple/group_deps',\n",
       " 'gradients/h1/MatMul_grad/tuple/control_dependency',\n",
       " 'gradients/h1/MatMul_grad/tuple/control_dependency_1',\n",
       " 'global_norm/L2Loss',\n",
       " 'global_norm/L2Loss_1',\n",
       " 'global_norm/L2Loss_2',\n",
       " 'global_norm/L2Loss_3',\n",
       " 'global_norm/stack',\n",
       " 'global_norm/Const',\n",
       " 'global_norm/Sum',\n",
       " 'global_norm/Const_1',\n",
       " 'global_norm/mul',\n",
       " 'global_norm/global_norm',\n",
       " 'clip_by_global_norm/truediv/x',\n",
       " 'clip_by_global_norm/truediv',\n",
       " 'clip_by_global_norm/Const',\n",
       " 'clip_by_global_norm/truediv_1/y',\n",
       " 'clip_by_global_norm/truediv_1',\n",
       " 'clip_by_global_norm/Minimum',\n",
       " 'clip_by_global_norm/mul/x',\n",
       " 'clip_by_global_norm/mul',\n",
       " 'clip_by_global_norm/mul_1',\n",
       " 'clip_by_global_norm/clip_by_global_norm/_0',\n",
       " 'clip_by_global_norm/mul_2',\n",
       " 'clip_by_global_norm/clip_by_global_norm/_1',\n",
       " 'clip_by_global_norm/mul_3',\n",
       " 'clip_by_global_norm/clip_by_global_norm/_2',\n",
       " 'clip_by_global_norm/mul_4',\n",
       " 'clip_by_global_norm/clip_by_global_norm/_3',\n",
       " 'h1/kernel/Adagrad/Initializer/Const',\n",
       " 'h1/kernel/Adagrad',\n",
       " 'h1/kernel/Adagrad/Assign',\n",
       " 'h1/kernel/Adagrad/read',\n",
       " 'h1/bias/Adagrad/Initializer/Const',\n",
       " 'h1/bias/Adagrad',\n",
       " 'h1/bias/Adagrad/Assign',\n",
       " 'h1/bias/Adagrad/read',\n",
       " 'nah_predicted/kernel/Adagrad/Initializer/Const',\n",
       " 'nah_predicted/kernel/Adagrad',\n",
       " 'nah_predicted/kernel/Adagrad/Assign',\n",
       " 'nah_predicted/kernel/Adagrad/read',\n",
       " 'nah_predicted/bias/Adagrad/Initializer/Const',\n",
       " 'nah_predicted/bias/Adagrad',\n",
       " 'nah_predicted/bias/Adagrad/Assign',\n",
       " 'nah_predicted/bias/Adagrad/read',\n",
       " 'Adagrad/learning_rate',\n",
       " 'Adagrad/update_h1/kernel/Cast',\n",
       " 'Adagrad/update_h1/kernel/ApplyAdagrad',\n",
       " 'Adagrad/update_h1/bias/Cast',\n",
       " 'Adagrad/update_h1/bias/ApplyAdagrad',\n",
       " 'Adagrad/update_nah_predicted/kernel/Cast',\n",
       " 'Adagrad/update_nah_predicted/kernel/ApplyAdagrad',\n",
       " 'Adagrad/update_nah_predicted/bias/Cast',\n",
       " 'Adagrad/update_nah_predicted/bias/ApplyAdagrad',\n",
       " 'Adagrad',\n",
       " 'accuracy/correct_prediction/ArgMax/dimension',\n",
       " 'accuracy/correct_prediction/ArgMax',\n",
       " 'accuracy/correct_prediction/ArgMax_1/dimension',\n",
       " 'accuracy/correct_prediction/ArgMax_1',\n",
       " 'accuracy/correct_prediction/Equal',\n",
       " 'accuracy/accuracy/Cast',\n",
       " 'accuracy/accuracy/Const',\n",
       " 'accuracy/accuracy/Mean',\n",
       " 'accuracy/accuracy_1/tags',\n",
       " 'accuracy/accuracy_1',\n",
       " 'Merge/MergeSummary',\n",
       " 'init',\n",
       " 'save/Const',\n",
       " 'save/SaveV2/tensor_names',\n",
       " 'save/SaveV2/shape_and_slices',\n",
       " 'save/SaveV2',\n",
       " 'save/control_dependency',\n",
       " 'save/RestoreV2/tensor_names',\n",
       " 'save/RestoreV2/shape_and_slices',\n",
       " 'save/RestoreV2',\n",
       " 'save/Assign',\n",
       " 'save/Assign_1',\n",
       " 'save/Assign_2',\n",
       " 'save/Assign_3',\n",
       " 'save/Assign_4',\n",
       " 'save/Assign_5',\n",
       " 'save/Assign_6',\n",
       " 'save/Assign_7',\n",
       " 'save/restore_all']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "([n.name for n in graph.as_graph_def().node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"nah_predicted/BiasAdd:0\", shape=(?, 300), dtype=float64)\n",
      "(1500, 300)\n"
     ]
    }
   ],
   "source": [
    "output_NN = graph.get_tensor_by_name(\"nah_predicted/BiasAdd:0\")\n",
    "#output_NN = graph.get_tensor_by_name(\"nah_predicted:0\")\n",
    "#code = graph.get_tensor_by_name(\"xw_plus_b_2:0\")\n",
    "print(output_NN)\n",
    "\n",
    "feed_dict = {X: test_vectors, kprob: 1}\n",
    "pred = sess.run(output_NN, feed_dict)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 28s, sys: 4min 15s, total: 9min 43s\n",
      "Wall time: 3min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "top_10 = [utils.get_top10_vectors(pred[_], target_vec) for _ in range(pred.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 ms, sys: 1.42 ms, total: 15.4 ms\n",
      "Wall time: 168 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "closest = [utils.closest_word_to(top_10[_], words_trg) for _ in range(pred.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = {palabra_en: top_10_it for (palabra_en, top_10_it) in zip(eval_src, closest)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = utils.gold_dict(words_scr_lexicon, words_trg_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found: 671 - 0.44733333333333336 %\n",
      "P@1: 505 \tP@5: 769 \tP@10: 829\n",
      "P@1: 0.33666666666666667 \tP@5: 0.5126666666666667 \tP@10: 0.5526666666666666\n",
      "CPU times: user 4.05 ms, sys: 28 ¬µs, total: 4.07 ms\n",
      "Wall time: 3.96 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p1, p5, p10 = 0, 0, 0\n",
    "list_en_eval = list(resultados.keys())\n",
    "hits, not_found = [], []\n",
    "\n",
    "for palabra_gold in list_en_eval:\n",
    "    for i in gold[palabra_gold]:\n",
    "        if i in resultados[palabra_gold]:\n",
    "            hits.append(resultados[palabra_gold].index(i))\n",
    "    if hits.__len__() > 0:\n",
    "        if min(hits) == 0:\n",
    "            p1 += 1\n",
    "            p5 += 1\n",
    "            p10 += 1\n",
    "        if min(hits) >= 1 and min(hits) <= 5:\n",
    "            p5 += 1\n",
    "            p10 += 1\n",
    "        if min(hits) > 5 and min(hits) < 10:\n",
    "            p10 += 1\n",
    "    else:\n",
    "        not_found.append(palabra_gold)\n",
    "    hits.clear()\n",
    "\n",
    "length = list_en_eval.__len__()\n",
    "print(\"not found:\", not_found.__len__(), \"-\", not_found.__len__() / length, \"%\")\n",
    "print(\"P@1:\", p1, \"\\tP@5:\", p5, \"\\tP@10:\", p10)\n",
    "print(\"P@1:\", p1 / length, \"\\tP@5:\", p5 /length, \"\\tP@10:\", p10 / length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
