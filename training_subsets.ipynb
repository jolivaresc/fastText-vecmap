{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import io\n",
    "import numpy as np\n",
    "import utils\n",
    "from zipfile import ZipFile\n",
    "from collections import Counter\n",
    "\n",
    "__author__ = \"Olivares Castillo José Luis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(file, threshold=0, vocabulary=None, dtype='float'):\n",
    "    header = file.readline().split(' ')\n",
    "    count = int(header[0]) if threshold <= 0 else min(threshold, int(header[0]))\n",
    "    dim = int(header[1])\n",
    "    words = []\n",
    "    matrix = np.empty((count, dim), dtype=dtype) if vocabulary is None else []\n",
    "    for i in range(count):\n",
    "        word, vec = file.readline().split(' ', 1)\n",
    "        if vocabulary is None:\n",
    "            words.append(word)\n",
    "            matrix[i] = np.fromstring(vec, sep=' ', dtype=dtype)\n",
    "        elif word in vocabulary:\n",
    "            words.append(word)\n",
    "            matrix.append(np.fromstring(vec, sep=' ', dtype=dtype))\n",
    "    return (words, matrix) if vocabulary is None else (words, np.array(matrix, dtype=dtype))\n",
    "\n",
    "def get_vectors(lexicon, words, embeddings, dtype='float'):\n",
    "    \"\"\"Función para cargar vectores del lexicon indicado.\n",
    "    Arguments:\n",
    "        lexicon {list} -- lista de palabras del lexicon\n",
    "        words {list} -- lista con palabras de los vectores.\n",
    "        embeddings {numpy.ndarray} -- matriz con embeddings\n",
    "    Return:\n",
    "        numpy.ndarray -- Matriz con embeddings del lexicon\n",
    "    \"\"\"\n",
    "    matrix = np.empty((len(lexicon), embeddings.shape[1]), dtype=dtype)\n",
    "    for i in range(len(lexicon)):\n",
    "        if lexicon[i] in words:\n",
    "            matrix[i] = embeddings[words.index(lexicon[i])]\n",
    "    return np.asarray(matrix, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 496)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src,trg=utils.get_lexicon(\"es-na.train\")\n",
    "len(src),len(trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 128)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_vec = open(\"datasets/es-na/es.node2vec.norm.embeddings\",errors=\"surrogateescape\")\n",
    "words_en,en_vec=read(source_vec)\n",
    "src_vec=get_vectors(src,words_en,en_vec)\n",
    "src_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 128)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vec = open(\"datasets/es-na/na.node2vec.norm.embeddings\",errors=\"surrogateescape\")\n",
    "words_trg,target_vec=read(target_vec)\n",
    "trg_vec=get_vectors(trg,words_trg,target_vec)\n",
    "trg_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/es-na/es.496.128d.train.norm.n2v\",\"w\") as file:\n",
    "    for i in range(src_vec.shape[0]):\n",
    "        #file.write(en[i]+\" \"+\" \".join(map(str,src_vec[i]))+\"\\n\")it-train.5k.300d.embeddings\n",
    "        if i.__ne__(src_vec.shape[0] - 1):\n",
    "            file.write(src[i]+\" \"+\" \".join(map(str,src_vec[i]))+\"\\n\")\n",
    "        else:\n",
    "            file.write(src[i]+\" \"+\" \".join(map(str,src_vec[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/es-na/na.496.128d.train.norm.n2v\",\"w\") as file:\n",
    "    for i in range(trg_vec.shape[0]):\n",
    "        #file.write(en[i]+\" \"+\" \".join(map(str,src_vec[i]))+\"\\n\")\n",
    "        if i.__ne__(trg_vec.shape[0] - 1):\n",
    "            file.write(trg[i]+\" \"+\" \".join(map(str,trg_vec[i]))+\"\\n\")\n",
    "        else:\n",
    "            file.write(trg[i]+\" \"+\" \".join(map(str,trg_vec[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lex,trg_lex = utils.get_lexicon(\"en-it.train\")\n",
    "len((src_lex)),len((trg_lex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = Counter(trg_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd[\"per\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesrc = open(\"datasets/en.200k.300d.fst\",\"r\")\n",
    "wordssrc, vecsrc = read(filesrc,vocabulary=Counter(src_lex),is_zipped=False)\n",
    "vecsrc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filetrg = open(\"datasets/en-it/it.200k.300d.fst\",\"r\",encoding=\"utf-8\")\n",
    "wordstrg, vectrg = read(filetrg,vocabulary=Counter(trg_lex),is_zipped=False)\n",
    "vectrg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lex[0],trg_lex[0],wordssrc[0],wordstrg[0],vectrg[0][:2],vectrg[3][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[wordstrg[i] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectrg[0],vectrg[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecsrc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(path,matrix,lex):\n",
    "    with open(path,\"w\",encoding=\"utf-8\") as f:\n",
    "        for _ in range(matrix.shape[0]):\n",
    "            if _.__ne__(matrix.shape[0]-1):\n",
    "                f.write(lex[_]+\" \"+\" \".join(map(str,matrix[_]))+\"\\n\")\n",
    "            else:\n",
    "                f.write(lex[_]+\" \"+\" \".join(map(str,matrix[_])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(path=\"datasets/en-it/en.5k.300d.fst\",matrix=vecsrc,lex=src_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(path=\"datasets/en-it/it.5k.300d.fst\",matrix=vectrg,lex=trg_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vec.shape,len(src_words),src_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm=list(set(src_lex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[tm,src_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[set(a) for a in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=0\n",
    "for i in tm:\n",
    "    if i not in src_words:\n",
    "        print(i)\n",
    "        w+=1\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1310+190"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
